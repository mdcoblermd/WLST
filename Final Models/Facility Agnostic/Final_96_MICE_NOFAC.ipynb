{"cells":[{"cell_type":"code","execution_count":null,"id":"332b9791","metadata":{"id":"332b9791"},"outputs":[],"source":["##install and import necessary modules\n","##this code was originally designed and run in google colab\n","##use outside of colab may require modification\n","##if using colab, you may need to restart your runtime after installing modules,\n","##depending on enviornment at time of code running.\n","\n","!pip install scikit-learn==1.5.2\n","!pip install tensorflow==2.12.1\n","!pip install xgboost==2.0.2\n","!pip install shap\n","import shap\n","import sys\n","import sklearn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import xgboost as xgb\n","import seaborn as sn\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n","from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc as sk_auc, precision_recall_curve, recall_score, confusion_matrix, brier_score_loss\n","from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.ensemble import RandomForestRegressor\n","\n","sn.set(style='whitegrid')\n","\n","print(\"Python version:\", sys.version)\n","print(\"scikit-learn version:\", sklearn.__version__)\n","print(\"XGBoost version:\", xgb.__version__)\n","print(\"shap version:\", shap.__version__)"]},{"cell_type":"code","execution_count":null,"id":"Ik3aE1RPVETF","metadata":{"id":"Ik3aE1RPVETF"},"outputs":[],"source":["##import your dataset\n","##mount google drive if using in colab. Replace <MOUNT_POINT> with the directory where you want to mount the drive (e.g., /content/drive).\n","drive.mount('<MOUNT_POINT>')\n","\n","# Replace <YOUR_FILE_PATH> with the actual path inside your Google Drive (e.g., My Drive/FileNameHere).\n","file_path = '<MOUNT_POINT>/<YOUR_FILE_PATH>.csv'"]},{"cell_type":"code","execution_count":null,"id":"a9e8e1be","metadata":{"id":"a9e8e1be"},"outputs":[],"source":["# Import data and specify missing values\n","data = pd.read_csv(file_path, na_values=['NA', 'N/A', 'NULL', ' ', '', '-99', '-98', '-99.0', '-99.00', '-98.0', '-98.00', 'NaN'])\n","\n","# Filter out rows where 'TRAUMATYPE' is 26, 'Other/unspecified', or 'Burn'\n","try:\n","  exclude_values = ['26', 'Other/unspecified', 'Burn']\n","  data = data[~data['TRAUMATYPE'].isin(exclude_values)]\n","except:\n","  pass"]},{"cell_type":"code","execution_count":null,"id":"522c0982","metadata":{"id":"522c0982"},"outputs":[],"source":["##check dataframe to ensure it appears as it should\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"ab349743","metadata":{"id":"ab349743"},"outputs":[],"source":["##check for missing data\n","data.isnull().sum(axis=0)"]},{"cell_type":"code","execution_count":null,"id":"e0ad2ed6","metadata":{"id":"e0ad2ed6"},"outputs":[],"source":["##create a dataframe of all complications/things not available on admission.  We can remove all of these from the X data set and pick one to be\n","#our Y dataset\n","\n","complications_df=pd.DataFrame()\n","complications_list= [\n","                    'HC_CLABSI', 'HC_DEEPSSI', 'HC_DVTHROMBOSIS', 'HC_ALCOHOLWITHDRAWAL', 'HC_CARDARREST', 'HC_CAUTI',\n","                    'HC_EMBOLISM', 'HC_EXTREMITYCS', 'HC_INTUBATION', 'HC_KIDNEY', 'HC_MI', 'HC_ORGANSPACESSI',\n","                    'HC_OSTEOMYELITIS', 'HC_RESPIRATORY', 'HC_RETURNOR', 'HC_SEPSIS', 'HC_STROKECVA', 'HC_SUPERFICIALINCISIONSSI',\n","                    'HC_PRESSUREULCER', 'HC_UNPLANNEDICU', 'HC_VAPNEUMONIA',\n","                    ##'EDDISCHARGEDISPOSITION',\n","                    'HOSPDISCHARGEDISPOSITION',\n","                    ##'EDDISCHARGEHRS',\n","                    'WITHDRAWALLST',\n","                    # 'VTEPROPHYLAXISTYPE',\n","                    'TOTALICULOS',\n","                    'TOTALVENTDAYS',\n","                    'VTEPROPHYLAXISHRS',\n","                    'VTEPROPHYLAXISDAYS', 'MORTALITY', 'EDDISCHARGEDAYS','FINALDISCHARGEDAYS','FINALDISCHARGEHRS', 'HMRRHGCTRLSURGDAYS',  'WITHDRAWALLSTHRS',\n","                    'AMERICANINDIAN', 'ASIAN', 'BLACK', 'PACIFICISLANDER', 'RACEOTHER', 'WHITE', 'RACE_NA', 'RACE_UK',\n","                    'TM_GROUNDAMBULANCE', 'TM_HELICOPTERAMBULANCE', 'TM_FIXEDWINGAMBULANCE', 'TM_PRIVPUBVEHWALKIN', 'TM_POLICE', 'TM_OTHER', 'TM_NA', 'TM_UK',\n","                    'ISS_05'\n","                    , 'AIS_FACE', 'AIS_NECK', 'AIS_HEAD', 'AIS_THORAX', 'AIS_ABDOMEN', 'AIS_SPINE', 'AIS_UPPEREX', 'AIS_LOWEREX', 'AIS_SKIN', 'AIS_OTHER'\n","                    # , 'VTEPPXStartOver48', 'VTEPPXStartOver24', 'ICUOver48', 'ICUOver24', 'VentOver48', 'VentOver24'\n","                    # , 'VTEPPXStartOver72', 'VTEPPXStartOver96', 'ICUOver72', 'ICUOver96', 'VentOver72', 'VentOver96'\n","                    , 'FacilityTotalWLST', 'factilityTotalPatients', 'FacilityWLSTRate', 'FacilityKey'\n","                    , 'facilityWLSTNew', 'WLSTRateNew', 'WLSTRateNewCensored'\n","                    , \"facilityPatientsNew\", \"WLSTRateCensorNormal\", \"HOSPITALTYPE\", \"STATEDESIGNATION\", \"TEACHINGSTATUS\", \"VERIFICATIONLEVEL\"\n","                    ]\n","for c in complications_list:\n","    complications_df[c] = data[c]\n","# complications_df"]},{"cell_type":"code","execution_count":null,"id":"8650e14e","metadata":{"id":"8650e14e"},"outputs":[],"source":["##this is where we choose our outcome variable, in this case, WLST, and move it to a separate dataframe\n","Y_data = pd.DataFrame()\n","Y_data['WLST'] = data['WITHDRAWALLST']\n","Y_data"]},{"cell_type":"code","execution_count":null,"id":"75be5241","metadata":{"id":"75be5241"},"outputs":[],"source":["##clean Y_data by replacing \"Yes\" and \"No\" vcalues with 0's and 1's\n","\n","Y_data['WLST'] = Y_data['WLST'].replace({'Yes': 1, 'No': 0})\n","Y_data"]},{"cell_type":"code","execution_count":null,"id":"90944eb8","metadata":{"id":"90944eb8"},"outputs":[],"source":["##remove all unwanted variables as defined above from the input space\n","X_data = data.drop(columns=complications_list)\n","X_data.shape"]},{"cell_type":"code","execution_count":null,"id":"eh992q4ujyp7","metadata":{"id":"eh992q4ujyp7"},"outputs":[],"source":["##need to remove any cases with missing data for our outcome variable\n","Missing_Y = Y_data.isnull().sum(axis=0)\n","Missing_Y"]},{"cell_type":"code","execution_count":null,"id":"73arQ_SPj1Iy","metadata":{"id":"73arQ_SPj1Iy"},"outputs":[],"source":["##here we find which rows in Y have missing values\n","\n","bad_row_index_list=[]\n","for n in range(0, Y_data.shape[0]):\n","    n_missings=Y_data.iloc[n,:].isnull().sum()\n","    if n_missings>0:\n","        bad_row_index_list.append(n)\n","bad_row_index_list"]},{"cell_type":"code","execution_count":null,"id":"b9270983","metadata":{"id":"b9270983"},"outputs":[],"source":["##now remove the bad rows in Y\n","Y_clean = Y_data.drop(bad_row_index_list, axis=0)\n","Y_clean"]},{"cell_type":"code","execution_count":null,"id":"ZWG9Tdo_gk5e","metadata":{"id":"ZWG9Tdo_gk5e"},"outputs":[],"source":["##ensure all cases with missing values for the outcome have been dropped\n","Missing_Y_clean = Y_clean.isnull().sum(axis=0)\n","Missing_Y_clean"]},{"cell_type":"code","execution_count":null,"id":"M4GwsrAqj_r2","metadata":{"id":"M4GwsrAqj_r2"},"outputs":[],"source":["##and remove bad rows in X\n","X_data=X_data.drop(bad_row_index_list, axis=0)"]},{"cell_type":"code","execution_count":null,"id":"Vh_ZoLAhQrng","metadata":{"id":"Vh_ZoLAhQrng"},"outputs":[],"source":["# Rename the 'TRAUMATYPE' column to 'Penetrating' and map the values to 0 and 1\n","X_data['Penetrating'] = X_data['TRAUMATYPE'].map({'Penetrating': 1, 'Blunt': 0})\n","\n","# Drop the old 'TRAUMATYPE' column\n","X_data.drop(columns=['TRAUMATYPE'], inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"zmsOgiisQ4RV","metadata":{"id":"zmsOgiisQ4RV"},"outputs":[],"source":["##drop patient record number as its not useful in making predictions\n","\n","columns_to_remove = ['inc_key']\n","X_data = X_data.drop(columns=columns_to_remove, errors='ignore')"]},{"cell_type":"code","execution_count":null,"id":"5FqhaevYRJBK","metadata":{"id":"5FqhaevYRJBK"},"outputs":[],"source":["##first we will convert No's and Yes's to 0's and 1's to minimize the amount of double variables (want to avoid Yes/Nos being converted to 1-hot variables)\n","##want code to be reusable between different populations of input data.  Not every population will have all of these variables\n","##Therefore, will do everything within separate try/except blocks\n","\n","try:\n","    X_data= X_data.replace({True: 1, 'Yes': 1, \"Female\": 1, False: 0, 'No': 0, \"Male\": 0})\n","except:\n","    pass\n","try:\n","    X_data['ETHNICITY'] = X_data['ETHNICITY'].replace({'Hispanic or Latino': 1, 'Not Hispanic or Latino': 0})\n","except:\n","    pass\n","try:\n","    X_data['EMSGCSEYE'] = X_data['EMSGCSEYE'].replace({'None': 1, 'To pressure': 2, 'To sound': 3,\n","                                                               'Spontaneous': 4})\n","except:\n","    pass\n","try:\n","    X_data['GCSEYE'] = X_data['GCSEYE'].replace({'None': 1, 'To pressure': 2, 'To sound': 3, 'Spontaneous': 4})\n","except:\n","    pass\n","try:\n","    X_data['EMSGCSVERBAL'] = X_data['EMSGCSVERBAL'].replace({'None': 1, 'Sounds': 2, 'Words': 3,\n","                                                                     'Confused': 4, 'Oriented': 5})\n","except:\n","    pass\n","try:\n","    X_data['EMSGCSMOTOR'] = X_data['EMSGCSMOTOR'].replace({'None': 1, 'Extension': 2, 'Abnormal Flexion': 3,\n","                                                                 'Normal Flexion': 4, 'Localising': 5, 'Obeys commands': 6})\n","except:\n","    pass\n","try:\n","    X_data['TBIGCSMOTOR'] = X_data['TBIGCSMOTOR'].replace({'None': 1, 'Extension': 2, 'Abnormal Flexion': 3,\n","                                                                 'Normal Flexion': 4, 'Localising': 5, 'Obeys commands': 6})\n","except:\n","    pass\n","try:\n","    X_data['GCSVERBAL'] = X_data['GCSVERBAL'].replace({'None': 1, 'Sounds': 2, 'Words': 3,\n","                                                               'Confused': 4, 'Orientated': 5})\n","except:\n","    pass\n","try:\n","    X_data['GCSMOTOR'] = X_data['GCSMOTOR'].replace({'None': 1, 'Extension': 2, 'Abnormal Flexion': 3,\n","                                                           'Normal Flexion': 4, 'Localising': 5, 'Obeys commands': 6})\n","except:\n","    pass\n","try:\n","    X_data['RESPIRATORYASSISTANCE'] = X_data['RESPIRATORYASSISTANCE'].replace({'Assisted Respiratory Rate': 1,\n","                                                                                   'Unassisted Respiratory Rate': 0})\n","except:\n","    pass\n","try:\n","    X_data['SUPPLEMENTALOXYGEN'] = X_data['SUPPLEMENTALOXYGEN'].replace({'Supplemental Oxygen': 1,\n","                                                                             'No Supplemental Oxygen': 0})\n","except:\n","    pass\n","\n","X_data.head()\n","\n","##male coded as 0\n","##female coded as 1\n","\n","##not hispanic coded as 0\n","##hispanic coded as 1"]},{"cell_type":"code","execution_count":null,"id":"X8qJPvjMR1Ca","metadata":{"id":"X8qJPvjMR1Ca"},"outputs":[],"source":["##replace boolean values in binary variables to numeric values\n","X_data = X_data.replace({True: 1, False: 0})"]},{"cell_type":"code","execution_count":null,"id":"088ce1ba","metadata":{"id":"088ce1ba"},"outputs":[],"source":["##check which variables in the input space have missing variables\n","Missing = X_data.isnull().sum(axis=0)\n","Missing[Missing>0]"]},{"cell_type":"code","execution_count":null,"id":"qaR1MA4zQX5n","metadata":{"id":"qaR1MA4zQX5n"},"outputs":[],"source":["##order variables with missing data by percentage\n","data_missing = (X_data.isnull().sum(axis=0)/X_data.shape[0]) * 100\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"FtR5sBNwQaDW","metadata":{"id":"FtR5sBNwQaDW"},"outputs":[],"source":["##display variables withOUT mising data\n","data_missing[data_missing == 0].index"]},{"cell_type":"code","execution_count":null,"id":"jCvUHe_RQbym","metadata":{"id":"jCvUHe_RQbym"},"outputs":[],"source":["#remove the good columns (no missing values) from data_missing\n","data_missing = data_missing.drop(data_missing[data_missing == 0].index)\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"5qbwbipXQdnA","metadata":{"id":"5qbwbipXQdnA"},"outputs":[],"source":["#sort this in ascending order\n","pd.set_option('display.max_rows', None)\n","data_missing = data_missing.sort_values(ascending=False)\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"pvKzlMEpQfcT","metadata":{"id":"pvKzlMEpQfcT"},"outputs":[],"source":["##prepare to drop variables with >50% missing values\n","dropCutoff=50\n","bad_column_names = data_missing[data_missing >=dropCutoff].index\n","bad_column_names"]},{"cell_type":"code","execution_count":null,"id":"uMsxdfhfQg2M","metadata":{"id":"uMsxdfhfQg2M"},"outputs":[],"source":["##actually drop bad variables\n","X_data_new=X_data.drop(columns=bad_column_names, axis=1)\n","\n","##check for which variables still have missing data (<50% missing values)\n","Missing = X_data_new.isnull().sum(axis=0)\n","Missing[Missing>0]"]},{"cell_type":"code","execution_count":null,"id":"HIBPbQv8QifC","metadata":{"id":"HIBPbQv8QifC"},"outputs":[],"source":["#check for columns with less than 50% missing that need to be cleaned\n","pd.set_option('display.max_rows', None)\n","to_be_cleaned_column_names = data_missing[data_missing <50].index\n","for col in X_data_new:\n","    print(col)"]},{"cell_type":"code","source":["continuous_vars = [\n","    \"AGEYEARS\", \"EMSPULSERATE\", \"EMSRESPIRATORYRATE\", \"EMSTOTALGCS\", \"EMSDISPATCHDAYS\",\n","    \"EMSSCENEHRS\", \"EMSSCENEDAYS\", \"EMSHRS\", \"EMSDAYS\", \"SBP\", \"PULSERATE\", \"TEMPERATURE\",\n","    \"RESPIRATORYRATE\", \"PULSEOXIMETRY\", \"HEIGHT\", \"WEIGHT\", \"TOTALGCS\", \"ALCOHOLSCREENRESULT\",\n","    \"EDDISCHARGEHRS\", \"TBIHIGHESTTOTALGCS\", \"TBIGCSMOTOR\", \"BLOODUNITS\", \"PLASMAUNITS\",\n","    \"NumberOfInjuries\", \"mFI\"\n","]\n","\n","categorical_vars = [\n","    \"SEX\", \"RACE\", \"ETHNICITY\", \"MECHANISM\", \"INTENT\", \"WORKRELATED\", \"ABUSEREPORT\",\n","    \"PROTDEV_NONE\", \"PROTDEV_LAP_BELT\", \"PROTDEV_PER_FLOAT\", \"PROTDEV_PROTECT_GEAR\",\n","    \"PROTDEV_EYE_PROTECT\", \"PROTDEV_CHILD_RESTRAINT\", \"PROTDEV_HELMET\", \"PROTDEV_AIRBAG_PRESENT\",\n","    \"PROTDEV_PROTECT_CLOTH\", \"PROTDEV_SHOULDER_BELT\", \"PROTDEV_OTHER\", \"PROTDEV_NA\", \"PROTDEV_UK\",\n","    \"AIRBAG_NOTDEPLOYED\", \"AIRBAG_DEPLOYED_FRNT\", \"AIRBAG_DEPLOYED_SIDE\", \"AIRBAG_DEPLOYED_OTHER\",\n","    \"AIRBAG_DEPLOYED_NA\", \"AIRBAG_DEPLOYED_UK\", \"TRANSPORTMODE\", \"INTERFACILITYTRANSFER\",\n","    \"PREHOSPITALCARDIACARREST\", \"TCCGCSLE13\", \"TCC10RR29\", \"TCCPEN\", \"TCCCHEST\", \"TCCLONGBONE\",\n","    \"TCCCRUSHED\", \"TCCAMPUTATION\", \"TCCPELVIC\", \"TCCSKULLFRACTURE\", \"TCCPARALYSIS\", \"TCC_NA\",\n","    \"TCC_UK\", \"VPOFALLADULT\", \"VPOFALLCHILD\", \"VPOCRASHINTRUSION\", \"VPOCRASHEJECT\",\n","    \"VPOCRASHDEATH\", \"VPOCRASHTELEMETRY\", \"VPOAUTOPEDIMPACT\", \"VPOMOTORCYCLECRASH\",\n","    \"VPO65SBP110\", \"VPOANTICOAGULANT\", \"VPOPREGNANCY20WKS\", \"VPOEMSJUDGE\", \"VPOBURNS\",\n","    \"VPOTRAUMABURNS\", \"VPO_NA\", \"VPO_UK\", \"RESPIRATORYASSISTANCE\", \"SUPPLEMENTALOXYGEN\",\n","    \"GCSQ_SEDATEDPARALYZED\", \"GCSQ_EYEOBSTRUCTION\", \"GCSQ_INTUBATED\", \"GCSQ_VALID\", \"GCSQ_NA\",\n","    \"GCSQ_UK\", \"DRGSCR_AMPHETAMINE\", \"DRGSCR_BARBITURATE\", \"DRGSCR_BENZODIAZEPINES\",\n","    \"DRGSCR_COCAINE\", \"DRGSCR_METHAMPHETAMINE\", \"DRGSCR_ECSTASY\", \"DRGSCR_METHADONE\",\n","    \"DRGSCR_OPIOID\", \"DRGSCR_OXYCODONE\", \"DRGSCR_PHENCYCLIDINE\", \"DRGSCR_TRICYCLICDEPRESS\",\n","    \"DRGSCR_CANNABINOID\", \"DRGSCR_OTHER\", \"DRGSCR_NONE\", \"DRGSCR_NOTTESTED\", \"DRGSCR_UK\",\n","    \"DRGSCR_NA\", \"ALCOHOLSCREEN\", \"EDDISCHARGEDISPOSITION\", \"DEATHINED\", \"TBIPUPILLARYRESPONSE\",\n","    \"TBIMIDLINESHIFT\", \"PMGCSQ_SEDATEDPARALYZED\", \"PMGCSQ_EYEOBSTRUCTION\", \"PMGCSQ_INTUBATED\",\n","    \"PMGCSQ_VALID\", \"PMGCSQ_NA\", \"PMGCSQ_UK\", \"ICPEVDRAIN\", \"ICPPARENCH\", \"ICPO2MONITOR\",\n","    \"ICPJVBULB\", \"ICPNONE\", \"ICP_NA\", \"ICP_UK\", \"BLOODBINARY\", \"PLASMABINARY\", \"PLATELETSBINARY\",\n","    \"CRYOBINARY\", \"ESLIVER\", \"ESSPLEEN\", \"ESKIDNEY\", \"ESPELVIS\", \"ESRETROPERI\",\n","    \"ESVASCULAR\", \"ESAORTA\", \"ESOTHER\", \"ES_UK\", \"ES_NA\", \"PRIMARYMETHODPAYMENT\",\n","    \"CC_ADHD\", \"CC_ADLC\", \"CC_ALCOHOLISM\", \"CC_ANGINAPECTORIS\",\n","    \"CC_ANTICOAGULANT\", \"CC_BLEEDING\", \"CC_CHEMO\", \"CC_CIRRHOSIS\", \"CC_CONGENITAL\", \"CC_COPD\",\n","    \"CC_CVA\", \"CC_DEMENTIA\", \"CC_DIABETES\", \"CC_DISCANCER\", \"CC_FUNCTIONAL\", \"CC_CHF\",\n","    \"CC_HYPERTENSION\", \"CC_MI\", \"CC_PAD\", \"CC_PREMATURITY\", \"CC_MENTALPERSONALITY\", \"CC_RENAL\",\n","    \"CC_SMOKING\", \"CC_STEROID\", \"CC_SUBSTANCEABUSE\", \"IntracranialVascularInjury\", \"BrainStemInjury\",\n","    \"EDH\", \"SAH\", \"SDH\", \"SkullFx\", \"DAI\", \"NeckVascularInjury\", \"ThoracicVascularInjury\",\n","    \"AeroDigestiveInjury\", \"CardiacInjury\", \"LungInjury\", \"AbdominalVascular\", \"RibFx\",\n","    \"KidneyInjury\", \"StomachInjury\", \"SpleenInjury\", \"UroGenInternalInjury\", \"SCI\", \"SpineFx\",\n","    \"UEAmputation\", \"UEVascularInjury\", \"UELongBoneFx\", \"LEVascularInjury\", \"PelvicFx\",\n","    \"LEAmputation\", \"PancreasInjury\", \"LELongBoneFx\", \"LiverInjury\", \"ColorectalInjury\",\n","    \"SmallBowelInjury\", \"isolatedTBI\", \"missingGCS\", \"missingAge\", \"missingSex\", \"missingType\",\n","    \"missingSBP\", \"missingHR\", \"missingRR\", \"missingPulseOx\", \"missingHeight\", \"missingWeight\",\n","    \"missingEDDispo\", \"missingRBC\", \"missingPlasma\", \"Penetrating\",\n","    'VTEPPXStartOver48', 'VTEPPXStartOver24', 'ICUOver48', 'ICUOver24', 'VentOver48', 'VentOver24',\n","    'VTEPPXStartOver72', 'VTEPPXStartOver96', 'ICUOver72', 'ICUOver96', 'VentOver72', 'VentOver96', 'VTEPROPHYLAXISTYPE'\n","]\n","\n","# Continuous variables that must be integers\n","int_constrained_vars = [\n","    \"AGEYEARS\", \"EMSPULSERATE\", \"EMSRESPIRATORYRATE\", \"EMSTOTALGCS\", \"EMSDISPATCHDAYS\",\n","    \"EMSSCENEDAYS\", \"EMSDAYS\", \"SBP\", \"PULSERATE\", \"RESPIRATORYRATE\", \"PULSEOXIMETRY\",\n","    \"TOTALGCS\", \"TBIHIGHESTTOTALGCS\", \"TBIGCSMOTOR\", \"BLOODUNITS\", \"PLASMAUNITS\",\n","    \"NumberOfInjuries\", \"mFI\"\n","]\n","\n","time_pairs = [\n","    (\"EMSSCENEDAYS\", \"EMSSCENEHRS\"),\n","    (\"EMSDAYS\", \"EMSHRS\"),\n","]"],"metadata":{"id":"8jhnKpBUJW9C"},"id":"8jhnKpBUJW9C","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##verify shape of these arrays\n","\n","print(X_data_new.shape)\n","print(len(continuous_vars))\n","print(len(categorical_vars))"],"metadata":{"id":"lr5iE62SJ6Qr"},"id":"lr5iE62SJ6Qr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ───────────────────────────────────────────────────────────────────────────────\n","# 1) Start with your full feature matrix X_data_new and your outcome Y_clean.\n","# ───────────────────────────────────────────────────────────────────────────────\n","\n","X_full = X_data_new.copy()\n","# If Y_clean is a one-column DataFrame, extract it as a Series. Otherwise adjust accordingly.\n","Y_full = Y_clean.iloc[:, 0]\n","\n","# 2) Identify which columns are categorical / continuous / integer‐constrained.\n","categorical_mice = [c for c in categorical_vars if c in X_full.columns]\n","continuous_mice  = [c for c in continuous_vars  if c in X_full.columns]\n","int_mice         = [c for c in int_constrained_vars if c in X_full.columns]\n","\n","# 3) Convert any \"nan\" strings into real np.nan in the categorical columns.\n","X_full[categorical_mice] = (\n","    X_full[categorical_mice]\n","      .replace(\"nan\", np.nan)\n","      .astype(str)\n","      .replace(\"nan\", np.nan)\n",")\n","\n","# 4) Ordinal‐encode all categorical_mice columns at once (so train/test share the same mapping).\n","ordinal_encoder_mice = OrdinalEncoder(\n","    handle_unknown=\"use_encoded_value\",\n","    unknown_value=-1\n",")\n","X_full[categorical_mice] = ordinal_encoder_mice.fit_transform(X_full[categorical_mice])\n","\n","# 5) Now do the first split: full → (train_raw, test_raw).\n","#    Since outcome is binary, we can stratify on it to ensure similar split between groups.\n","X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(\n","    X_full,\n","    Y_full,\n","    test_size=0.20,\n","    random_state=0,\n","    stratify=Y_full\n",")\n","\n","##sanity check to ensure appropriate dataframe shape\n","print(\" Completed train/test split:\")\n","print(f\"   X_train_raw: {X_train_raw.shape}, X_test_raw: {X_test_raw.shape}\")\n","print(f\"   Y_train: {Y_train.shape},      Y_test: {Y_test.shape}\")\n","\n","# 6) Next, split X_train_raw + Y_train into (train_for_impute_raw, calibration_raw).\n","#    We'll use calibration_raw later to calibrate the model.\n","#    Use stratification here as well (since Y_train is still binary).\n","X_train_for_impute_raw, X_cal_raw, Y_train_for_impute, Y_cal = train_test_split(\n","    X_train_raw,\n","    Y_train,\n","    test_size=0.20,\n","    random_state=0,\n","    stratify=Y_train\n",")\n","\n","##additional sanity check to ensure appropriate dataframe shape\n","print(\"\\n Split train_raw into train_for_impute and calibration:\")\n","print(f\"   X_train_for_impute_raw: {X_train_for_impute_raw.shape}, Y_train_for_impute: {Y_train_for_impute.shape}\")\n","print(f\"   X_cal_raw: {X_cal_raw.shape},            Y_cal: {Y_cal.shape}\")\n"],"metadata":{"id":"1jyZsMwoXq50"},"id":"1jyZsMwoXq50","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#this code is used to load imputed datasets that were previously generated from the hyperparameter files\n","\n","#set folder with saved imputed datasets, as pickle files.\n","# replace <YOUR_SAVE_DIR> with whereever your files are stored\n","save_dir = '<YOUR_SAVE_DIR>'\n","\n","## Now define a list of the 3 imputed datasets for each train,cal,test sets\n","train_names = [\"nofac_train_seed100_96\", \"nofac_train_seed200_96\", \"nofac_train_seed300_96\"]\n","cal_names   = [\"nofac_cal_seed100_96\",   \"nofac_cal_seed200_96\",   \"nofac_cal_seed300_96\"]\n","test_names  = [\"nofac_test_seed100_96\",  \"nofac_test_seed200_96\",  \"nofac_test_seed300_96\"]\n","\n","\n","# 3) Load into the same variables your pipeline expects:\n","imputed_X_train_list = [\n","    pd.read_pickle(f\"{save_dir}/{name}.pkl\") for name in train_names\n","]\n","imputed_X_cal_list = [\n","    pd.read_pickle(f\"{save_dir}/{name}.pkl\") for name in cal_names\n","]\n","imputed_X_test_list = [\n","    pd.read_pickle(f\"{save_dir}/{name}.pkl\") for name in test_names\n","]\n","\n","print(\"Reloaded imputed_X_train_list, imputed_X_cal_list, and imputed_X_test_list\")\n"],"metadata":{"id":"6bIh0kwcXnNz"},"id":"6bIh0kwcXnNz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now we generate descriptive statistics for pre- and  post-imputation to ensure\n","##similar distribution of data\n","\n","# Lists of imputed variables (must already exist in your notebook)\n","# continuous_mice = [ ... ]  # list of continuous columns that were imputed\n","# categorical_mice = [ ... ] # list of categorical columns that were imputed\n","\n","# -----------------------------------------------------------------------------\n","# Lets define a helper function to summarize continuous variables (mean, median, STD, IQR)\n","# -----------------------------------------------------------------------------\n","def summarise_continuous(df, vars_list):\n","    stats = []\n","    for var in vars_list:\n","        s = df[var].dropna()\n","        mean = s.mean()\n","        median = s.median()\n","        std = s.std()\n","        q1 = s.quantile(0.25)\n","        q3 = s.quantile(0.75)\n","        iqr = q3 - q1\n","        stats.append({\n","            'variable': var,\n","            'mean': mean,\n","            'median': median,\n","            'std': std,\n","            'IQR': iqr\n","        })\n","    return pd.DataFrame(stats).set_index('variable')\n","\n","# -----------------------------------------------------------------------------\n","# And same for categorical (mode, and % of dataset with that mode value)\n","# -----------------------------------------------------------------------------\n","def summarise_categorical(df, vars_list):\n","    summaries = {}\n","    for var in vars_list:\n","        counts = df[var].value_counts(dropna=True)\n","        props = counts / counts.sum()\n","        mode = df[var].mode(dropna=True)\n","        mode = mode.iloc[0] if not mode.empty else np.nan\n","        mode_prop = props.get(mode, np.nan)\n","        summaries[var] = {\n","            'mode': mode,\n","            'mode_proportion': mode_prop,\n","            'levels_proportions': props.to_dict()\n","        }\n","    return summaries\n","\n","# -----------------------------------------------------------------------------\n","# 1) Pre-imputation summaries on TRAIN_FOR_IMPUTE raw\n","# -----------------------------------------------------------------------------\n","pre_train = X_train_for_impute_raw.copy()\n","\n","cont_pre_summary = summarise_continuous(pre_train, continuous_mice)\n","cat_pre_summary = summarise_categorical(pre_train, categorical_mice)\n","\n","# -----------------------------------------------------------------------------\n","# 2) Post-imputation summaries (each of the 3 imputations on TRAIN_FOR_IMPUTE)\n","# -----------------------------------------------------------------------------\n","cont_post_list = []\n","cat_post_list = []\n","\n","for i, df_imp in enumerate(imputed_X_train_list):\n","    # 2a) Continuous stats for imputation i\n","    cont_stats = summarise_continuous(df_imp, continuous_mice).rename(\n","        columns=lambda c: f\"{c}_imp{i}\"\n","    )\n","    cont_post_list.append(cont_stats)\n","\n","    # 2b) Categorical stats (mode + mode proportion) for imputation i\n","    cat_stats = pd.DataFrame([\n","        {\n","            'variable': var,\n","            'mode_imp': df_imp[var].mode(dropna=True).iloc[0] if not df_imp[var].mode(dropna=True).empty else np.nan,\n","            'mode_prop_imp': df_imp[var].value_counts(normalize=True).get(\n","                df_imp[var].mode(dropna=True).iloc[0], np.nan\n","            )\n","        }\n","        for var in categorical_mice\n","    ]).set_index('variable').rename(columns=lambda c: f\"{c}_{i}\")\n","    cat_post_list.append(cat_stats)\n","\n","# 2c) Combine continuous stats across imputations\n","cont_post_summary = pd.concat(cont_post_list, axis=1)\n","\n","# 2d) Combine categorical stats across imputations\n","cat_post_summary = pd.concat(cat_post_list, axis=1)\n","\n","# -----------------------------------------------------------------------------\n","# 3) Display pre- vs post-imputation summaries for continuous\n","# -----------------------------------------------------------------------------\n","print(\"=== Continuous variables pre-imputation (TRAIN_FOR_IMPUTE) ===\")\n","display(cont_pre_summary)\n","\n","print(\"=== Continuous variables post-imputation (TRAIN_FOR_IMPUTE) ===\")\n","display(cont_post_summary)\n","\n","# -----------------------------------------------------------------------------\n","# 4) Display pre- vs post-imputation summaries for categorical\n","# -----------------------------------------------------------------------------\n","print(\"=== Categorical variables pre-imputation (TRAIN_FOR_IMPUTE) ===\")\n","for var, info in cat_pre_summary.items():\n","    print(\n","        f\"{var}: mode={info['mode']}, \"\n","        f\"mode_proportion={info['mode_proportion']:.3f}, \"\n","        f\"level_proportions={info['levels_proportions']}\"\n","    )\n","\n","print(\"\\n=== Categorical variables post-imputation (TRAIN_FOR_IMPUTE) ===\")\n","display(cat_post_summary)\n"],"metadata":{"id":"QGVRfvubMfjv"},"id":"QGVRfvubMfjv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ──────────────────────────────────────────────────────────────────────────────\n","# Sanity‐check A: For each imputed TRAIN/CAL/TEST, confirm categorical dtypes & cardinalities\n","# ──────────────────────────────────────────────────────────────────────────────\n","\n","for i in range(len(imputed_X_train_list)):\n","    print(f\"\\n--- Imputation {i} (TRAIN_FOR_IMPUTE) ---\")\n","    df_train = imputed_X_train_list[i]\n","\n","    # 1) Cardinality of each categorical_mice column\n","    card_train = df_train[categorical_mice].nunique().sort_values(ascending=False)\n","    print(\"  TRAIN_FOR_IMPUTE cardinalities:\\n\", card_train)\n","\n","    # 2) dtype of each categorical_mice column\n","    dtypes_train = df_train[categorical_mice].dtypes\n","    print(\"  TRAIN_FOR_IMPUTE dtypes:\\n\", dtypes_train)\n","\n","    print(f\"\\n--- Imputation {i} (CALIBRATION) ---\")\n","    df_cal = imputed_X_cal_list[i]\n","\n","    card_cal = df_cal[categorical_mice].nunique().sort_values(ascending=False)\n","    print(\"  CALIBRATION cardinalities:\\n\", card_cal)\n","\n","    dtypes_cal = df_cal[categorical_mice].dtypes\n","    print(\"  CALIBRATION dtypes:\\n\", dtypes_cal)\n","\n","    print(f\"\\n--- Imputation {i} (TEST) ---\")\n","    df_test = imputed_X_test_list[i]\n","\n","    card_test = df_test[categorical_mice].nunique().sort_values(ascending=False)\n","    print(\"  TEST cardinalities:\\n\", card_test)\n","\n","    dtypes_test = df_test[categorical_mice].dtypes\n","    print(\"  TEST dtypes:\\n\", dtypes_test)\n","\n","    print(\"─\" * 60)\n"],"metadata":{"id":"Y9MQ3v0BKs34"},"id":"Y9MQ3v0BKs34","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ──────────────────────────────────────────────────────────────────────────────\n","# Sanity‐check B: Ensure zero missing values in TRAIN_FOR_IMPUTE / CAL / TEST\n","# ──────────────────────────────────────────────────────────────────────────────\n","\n","for i in range(len(imputed_X_train_list)):\n","    df_train = imputed_X_train_list[i]\n","    n_missing_train = df_train.isnull().sum().sum()\n","\n","    df_cal = imputed_X_cal_list[i]\n","    n_missing_cal = df_cal.isnull().sum().sum()\n","\n","    df_test = imputed_X_test_list[i]\n","    n_missing_test = df_test.isnull().sum().sum()\n","\n","    print(f\"Imputation {i}:\")\n","    print(f\"  TRAIN_FOR_IMPUTE missing count = {n_missing_train}\")\n","    print(f\"  CALIBRATION missing count   = {n_missing_cal}\")\n","    print(f\"  TEST missing count          = {n_missing_test}\")\n","    print(\"─\" * 60)\n"],"metadata":{"id":"giEhapWAK_6v"},"id":"giEhapWAK_6v","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now we'll one-hot encode all categorical variables\n","\n","##define lists to store each imputed dataset\n","encoded_X_train_list = []\n","encoded_X_cal_list   = []\n","encoded_X_test_list  = []\n","\n","##now actually store copies of the imputed dataset in these lists\n","for i in range(len(imputed_X_train_list)):\n","    df_train_imp = imputed_X_train_list[i].copy()\n","    df_cal_imp   = imputed_X_cal_list[i].copy()\n","    df_test_imp  = imputed_X_test_list[i].copy()\n","\n","    # 1) Collect all categorical columns present in train_i, cal_i, or test_i\n","    categorical_columns = sorted(\n","        set(df_train_imp.select_dtypes(include=[\"category\", \"object\"]).columns.tolist())\n","        | set(df_cal_imp.select_dtypes(include=[\"category\", \"object\"]).columns.tolist())\n","        | set(df_test_imp.select_dtypes(include=[\"category\", \"object\"]).columns.tolist())\n","    )\n","    print(f\"Imputation {i}: found {len(categorical_columns)} categorical columns to encode.\")\n","\n","    # 2) Concatenate train_i + cal_i + test_i so that get_dummies runs once.\n","    df_combined = pd.concat([df_train_imp, df_cal_imp, df_test_imp], axis=0)\n","\n","    # 3) Loop through each categorical column and create dummies (drop or not as before):\n","    df_combined_enc = df_combined.copy()\n","    for col in categorical_columns:\n","        # Determine the actual levels (ignoring NaN)\n","        if isinstance(df_combined_enc[col].dtype, pd.CategoricalDtype):\n","            levels = list(df_combined_enc[col].cat.categories)\n","        else:\n","            levels = sorted(df_combined_enc[col].dropna().unique())\n","        levels = [lvl for lvl in levels if pd.notna(lvl)]\n","\n","        if len(levels) <= 1:\n","            df_combined_enc.drop(columns=[col], inplace=True)\n","            continue\n","\n","        if len(levels) == 2:\n","            # Binary: drop_first=True → one dummy column\n","            dummies = pd.get_dummies(df_combined_enc[col], prefix=col, drop_first=True)\n","            df_combined_enc = pd.concat(\n","                [df_combined_enc.drop(columns=[col]), dummies],\n","                axis=1\n","            )\n","        else:\n","            # Multi‐level: drop_first=False → full set of dummies\n","            dummies = pd.get_dummies(df_combined_enc[col], prefix=col, drop_first=False)\n","            df_combined_enc = pd.concat(\n","                [df_combined_enc.drop(columns=[col]), dummies],\n","                axis=1\n","            )\n","\n","    # 4) Split the encoded combined back into train_enc_i, cal_enc_i, test_enc_i by index\n","    df_train_enc_i = df_combined_enc.loc[df_train_imp.index].copy()\n","    df_cal_enc_i   = df_combined_enc.loc[df_cal_imp.index].copy()\n","    df_test_enc_i  = df_combined_enc.loc[df_test_imp.index].copy()\n","\n","    # 5) Verify that train_enc_i, cal_enc_i, and test_enc_i share the exact same columns:\n","    cols_train = set(df_train_enc_i.columns)\n","    cols_cal   = set(df_cal_enc_i.columns)\n","    cols_test  = set(df_test_enc_i.columns)\n","    if not (cols_train == cols_cal == cols_test):\n","        raise ValueError(f\"❌ Column mismatch in imputation {i} after dummy encoding!\")\n","    else:\n","        print(f\"Imputation {i}: train/cal/test columns match (n_cols={len(cols_train)})\")\n","\n","    encoded_X_train_list.append(df_train_enc_i)\n","    encoded_X_cal_list.append(df_cal_enc_i)\n","    encoded_X_test_list.append(df_test_enc_i)\n","\n","print(\"Completed one‐hot encoding for all 3 imputed sets.\")\n"],"metadata":{"id":"wdzUxjb5XrHc"},"id":"wdzUxjb5XrHc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ──────────────────────────────────────────────────────────────────────────────\n","# Sanity‐check C (revised): Check no missing values and preview encoded_X_train_list / encoded_X_test_list\n","# ──────────────────────────────────────────────────────────────────────────────\n","\n","pd.set_option(\"display.max_columns\", None)\n","\n","print(\"Checking for missing values in each one‐hot–encoded TRAIN_FOR_IMPUTE:\")\n","for i, X_enc in enumerate(encoded_X_train_list):\n","    total_na = X_enc.isnull().sum().sum()\n","    status = \"No missing\" if total_na == 0 else f\"{total_na} missing\"\n","    print(f\"  Encoded TRAIN_FOR_IMPUTE {i}: {status}\")\n","\n","print(\"\\nChecking for missing values in each one‐hot–encoded TEST:\")\n","for i, X_enc in enumerate(encoded_X_test_list):\n","    total_na = X_enc.isnull().sum().sum()\n","    status = \"No missing\" if total_na == 0 else f\"{total_na} missing\"\n","    print(f\"  Encoded TEST {i}: {status}\")\n","\n","# ──────────────────────────────────────────────────────────────────────────────\n","# Preview a few rows from each encoded DataFrame\n","# ──────────────────────────────────────────────────────────────────────────────\n","\n","for i, X_enc in enumerate(encoded_X_train_list):\n","    print(f\"\\nEncoded TRAIN_FOR_IMPUTE {i} (preview):\")\n","    display(X_enc.head())\n","    print(\"─\" * 80)\n","\n","for i, X_enc in enumerate(encoded_X_test_list):\n","    print(f\"\\nEncoded TEST {i} (preview):\")\n","    display(X_enc.head())\n","    print(\"─\" * 80)\n"],"metadata":{"id":"t-osr_CGLG_O"},"id":"t-osr_CGLG_O","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now ensure that the Y df indices match the X df indicies, so that each entry has the correct outcome\n","\n","for i in range(len(encoded_X_train_list)):\n","    Xtr = encoded_X_train_list[i]\n","    Xcal = encoded_X_cal_list[i]\n","    Xte = encoded_X_test_list[i]\n","\n","    # Check that Xtr.index == Y_train_for_impute.index\n","    if not Xtr.index.equals(Y_train_for_impute.index):\n","        print(f\"Imputation {i}: index mismatch between X_train_enc and Y_train_for_impute!\")\n","    else:\n","        print(f\"Imputation {i}: X_train_enc index matches Y_train_for_impute.\")\n","\n","    # Check that Xcal.index == Y_cal.index\n","    if not Xcal.index.equals(Y_cal.index):\n","        print(f\"Imputation {i}: index mismatch between X_cal_enc and Y_cal!\")\n","    else:\n","        print(f\"Imputation {i}: X_cal_enc index matches Y_cal.\")\n","\n","    # Check that Xte.index == Y_test.index\n","    if not Xte.index.equals(Y_test.index):\n","        print(f\"Imputation {i}: index mismatch between X_test_enc and Y_test!\")\n","    else:\n","        print(f\"Imputation {i}: X_test_enc index matches Y_test.\")\n","\n","    print(f\"   Shapes: X_train_enc_{i}={Xtr.shape}, X_cal_enc_{i}={Xcal.shape}, X_test_enc_{i}={Xte.shape}\")\n","    print(f\"           Y_train_for_impute={Y_train_for_impute.shape}, Y_cal={Y_cal.shape}, Y_test={Y_test.shape}\\n\")\n"],"metadata":{"id":"HNG8ti0yXrK6"},"id":"HNG8ti0yXrK6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#### Scale all continuous variables based on X_train\n","\n","X_train_s_list = []\n","X_cal_s_list   = []\n","X_test_s_list  = []\n","\n","for i in range(len(encoded_X_train_list)):\n","    Xtr = encoded_X_train_list[i].copy()\n","    Xcal = encoded_X_cal_list[i].copy()\n","    Xte = encoded_X_test_list[i].copy()\n","\n","    # Identify continuous columns (from your original continuous_vars)\n","    continuous_cols = [c for c in continuous_vars if c in Xtr.columns]\n","\n","    if len(continuous_cols) > 0:\n","        # ── a) Cast those columns to float64 on all three splits ─────────────────\n","        Xtr[continuous_cols] = Xtr[continuous_cols].astype(np.float64)\n","        Xcal[continuous_cols] = Xcal[continuous_cols].astype(np.float64)\n","        Xte[continuous_cols] = Xte[continuous_cols].astype(np.float64)\n","\n","        # ── b) Fit StandardScaler on Xtr[continuous_cols]\n","        scaler = StandardScaler()\n","        scaler.fit(Xtr[continuous_cols])\n","\n","        # ── c) Transform all three splits\n","        Xtr_scaled_vals = scaler.transform(Xtr[continuous_cols])\n","        Xcal_scaled_vals = scaler.transform(Xcal[continuous_cols])\n","        Xte_scaled_vals = scaler.transform(Xte[continuous_cols])\n","\n","        # ── d) Now assign back into the DataFrames (no dtype conflict)\n","        Xtr.loc[:, continuous_cols] = Xtr_scaled_vals\n","        Xcal.loc[:, continuous_cols] = Xcal_scaled_vals\n","        Xte.loc[:, continuous_cols] = Xte_scaled_vals\n","\n","    X_train_s_list.append(Xtr)\n","    X_cal_s_list.append(Xcal)\n","    X_test_s_list.append(Xte)\n","    print(f\"Imputation {i}: scaled continuous cols.   (X_train_s_{i}.shape={Xtr.shape})\")\n","\n","print(\"All imputed train/cal/test sets are now scaled.\")\n"],"metadata":{"id":"8MOgOQv-XrOS"},"id":"8MOgOQv-XrOS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##ensure DFs still have appropriate shape\n","\n","for i in range(len(X_train_s_list)):\n","    print(f\"--- Imputation {i} ---\")\n","    print(f\"X_train_s_{i}.shape = {X_train_s_list[i].shape}   (Y_train_for_impute.shape = {Y_train_for_impute.shape})\")\n","    print(f\"X_cal_s_{i}.shape   = {X_cal_s_list[i].shape}   (Y_cal.shape = {Y_cal.shape})\")\n","    print(f\"X_test_s_{i}.shape  = {X_test_s_list[i].shape}   (Y_test.shape = {Y_test.shape})\\n\")\n"],"metadata":{"id":"NEdMASc67y4f"},"id":"NEdMASc67y4f","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ──────────────────────────────────────────────────────────────\n","# Step 1: Make “safe” copies of your TRAIN and TEST data for XGBoost\n","# ──────────────────────────────────────────────────────────────\n","# Assume you have lists of imputed DataFrames: X_train_s_list, X_test_s_list\n","# and a single array/Series of labels before imputation: Y_train_for_impute, Y_test\n","\n","# Create safe‐named versions for each imputation\n","X_train_s_list_xgb = [\n","    df.copy().set_axis([f\"feat_{j}\" for j in range(df.shape[1])], axis=1)\n","    for df in X_train_s_list\n","]\n","X_test_s_list_xgb = [\n","    df.copy().set_axis([f\"feat_{j}\" for j in range(df.shape[1])], axis=1)\n","    for df in X_test_s_list\n","]\n","\n","# Build lists of numpy label arrays (one per imputation)\n","Y_train_list = [Y_train_for_impute.values for _ in X_train_s_list_xgb]\n","Y_test_list  = [Y_test.values for _ in X_test_s_list_xgb]\n","\n","# ──────────────────────────────────────────────────────────────\n","# Step 2: Specify your fixed hyperparameters from previous files\n","# ──────────────────────────────────────────────────────────────\n","fixed_params = {\n","    \"learning_rate\": 0.05,\n","    \"max_depth\": 7,\n","    \"n_estimators\": 200,\n","    \"colsample_bytree\": 0.8,\n","    \"subsample\": 0.8\n","}\n","\n","# ──────────────────────────────────────────────────────────────\n","# Step 3: Train on TRAIN and evaluate on TEST for each imputation\n","# ──────────────────────────────────────────────────────────────\n","test_auc_scores = []\n","\n","for i, (X_tr, X_te) in enumerate(zip(X_train_s_list_xgb, X_test_s_list_xgb)):\n","    y_tr = Y_train_list[i]\n","    y_te = Y_test_list[i]\n","\n","    # Initialize and fit the XGBoost model\n","    model = xgb.XGBClassifier(\n","        **fixed_params,\n","        use_label_encoder=False,\n","        eval_metric=\"logloss\",\n","        random_state=0\n","    )\n","    model.fit(X_tr, y_tr)\n","\n","    # Predict probabilities on the test set\n","    y_proba = model.predict_proba(X_te)[:, 1]\n","\n","    # Compute ROC AUC on this imputation’s test set\n","    auc = roc_auc_score(y_te, y_proba)\n","    test_auc_scores.append(auc)\n","    print(f\"Imputation {i} — Test ROC AUC: {auc:.4f}\")\n","\n","# Average AUC across imputations\n","mean_test_auc = float(np.mean(test_auc_scores))\n","print(f\"\\n>>> Mean Test ROC AUC (averaged over imputations): {mean_test_auc:.4f}\")\n","\n","\n","# ──────────────────────────────────────────────────────────────\n","# Store models in list\n","final_models = []\n","for i, X_tr in enumerate(X_train_s_list_xgb):\n","    y_tr = Y_train_list[i]\n","    model = xgb.XGBClassifier(\n","        **fixed_params,\n","        use_label_encoder=False,\n","        eval_metric=\"logloss\",\n","        random_state=0\n","    )\n","    model.fit(X_tr, y_tr)\n","    final_models.append(model)\n","\n","# Now `final_models` holds one trained XGBClassifier per imputation (to be calibrated later\n","# on your validation data as desired).\n"],"metadata":{"id":"rhL6c61376YO"},"id":"rhL6c61376YO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now calibrate all models on the validation/calibration set\n","# ──────────────────────────────────────────────────────────────\n","# Assume:\n","# - final_models is a list of pre-trained XGBClassifier instances\n","# - X_val_s_list_xgb is a list of “safe”-named validation DataFrames\n","#   corresponding to each imputation\n","# - Y_val_list is a list of numpy arrays/Series of validation labels\n","# ──────────────────────────────────────────────────────────────\n","\n","##make safe copies again, prevent anything from being overridden\n","X_cal_s_list_xgb = [\n","    df.copy().set_axis([f\"feat_{j}\" for j in range(df.shape[1])], axis=1)\n","    for df in X_cal_s_list\n","]\n","# Build lists of numpy label arrays (one per imputation)\n","Y_cal_list = [Y_cal.values for _ in X_cal_s_list_xgb]\n","\n","calibrated_models = []\n","val_auc_scores = []\n","\n","for i, base_model in enumerate(final_models):\n","    X_val = X_cal_s_list_xgb[i]\n","    y_val = Y_cal_list[i]\n","\n","    # Create a calibrated wrapper around the pre-trained model\n","    cal_model = CalibratedClassifierCV(\n","        estimator=base_model,\n","        method=\"isotonic\",\n","        cv=\"prefit\"\n","    )\n","    cal_model.fit(X_val, y_val)\n","    calibrated_models.append(cal_model)\n","\n","    # Compute validation ROC AUC after calibration\n","    y_val_proba = cal_model.predict_proba(X_val)[:, 1]\n","    auc_val = roc_auc_score(y_val, y_val_proba)\n","    val_auc_scores.append(auc_val)\n","    print(f\"Imputation {i} — Validation ROC AUC (calibrated): {auc_val:.4f}\")\n","\n","mean_val_auc = float(np.mean(val_auc_scores))\n","print(f\"\\n>>> Mean Validation ROC AUC (averaged over imputations): {mean_val_auc:.4f}\")\n"],"metadata":{"id":"jc67wE1mpPTv"},"id":"jc67wE1mpPTv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##genearte reliability diagrams for calibraiton with 95% CI\n","# ──────────────────────────────────────────────────────────────\n","# Assume the following are already defined:\n","# - final_models: list of isotonic‐calibrated XGBClassifier instances (one per imputation)\n","# - X_test_s_list_xgb: list of “safe”-named test DataFrames (one per imputation)\n","# - Y_test_list: list of numpy arrays of test labels (one per imputation)\n","# ──────────────────────────────────────────────────────────────\n","\n","\n","##define the function used to generate the curves)\n","def bootstrap_calibration_curve(y_true, y_prob, n_bins=10, n_boot=1000, random_state=None):\n","    \"\"\"\n","    1) Compute the original bin-based calibration curve.\n","    2) Bootstrap the dataset n_boot times, each time recalculating the bin-based\n","       fraction of positives (prob_true) and storing it.\n","    3) Return the original curve + 95% CI per bin (based on 2.5 and 97.5 percentiles).\n","    \"\"\"\n","    # Define bin edges (equally spaced from 0 to 1)\n","    bin_edges = np.linspace(0, 1, n_bins + 1)\n","\n","    # Digitize predicted probabilities\n","    bin_indices = np.digitize(y_prob, bin_edges) - 1\n","    bin_indices[bin_indices == n_bins] = n_bins - 1  # cap any == n_bins to last bin\n","\n","    # Prepare arrays to hold the original bin stats\n","    prob_pred_orig = np.zeros(n_bins)\n","    prob_true_orig = np.zeros(n_bins)\n","    counts_in_bin  = np.zeros(n_bins, dtype=int)\n","\n","    # Fill in the stats for each bin\n","    for i in range(n_bins):\n","        mask = (bin_indices == i)\n","        counts_in_bin[i] = np.sum(mask)\n","        if counts_in_bin[i] > 0:\n","            prob_pred_orig[i] = np.mean(y_prob[mask])   # mean predicted prob in this bin\n","            prob_true_orig[i] = np.mean(y_true[mask])   # fraction of positives (actual)\n","        else:\n","            prob_pred_orig[i] = np.nan\n","            prob_true_orig[i] = np.nan\n","\n","    # Remove empty bins (NaN) from the original arrays\n","    valid_mask = ~np.isnan(prob_pred_orig)\n","    prob_pred_orig = prob_pred_orig[valid_mask]\n","    prob_true_orig = prob_true_orig[valid_mask]\n","\n","    # -----------------------------\n","    # Bootstrap to get CIs\n","    # -----------------------------\n","    rng = np.random.RandomState(random_state) if random_state else np.random\n","\n","    # Store fraction of positives (prob_true) for each bin in each bootstrap\n","    boot_prob_true = np.zeros((n_boot, sum(valid_mask)))\n","    n_data = len(y_true)\n","\n","    for b in range(n_boot):\n","        sample_indices = rng.randint(0, n_data, size=n_data)\n","        y_true_b = y_true[sample_indices]\n","        y_prob_b = y_prob[sample_indices]\n","\n","        bin_indices_b = np.digitize(y_prob_b, bin_edges) - 1\n","        bin_indices_b[bin_indices_b == n_bins] = n_bins - 1\n","\n","        prob_true_b = np.zeros(n_bins)\n","        for i in range(n_bins):\n","            mask_b = (bin_indices_b == i)\n","            if mask_b.sum() > 0:\n","                prob_true_b[i] = np.mean(y_true_b[mask_b])\n","            else:\n","                prob_true_b[i] = np.nan\n","\n","        prob_true_b = prob_true_b[valid_mask]\n","        boot_prob_true[b, :] = prob_true_b\n","\n","    # Compute 2.5th and 97.5th percentile per bin\n","    lower_ci = np.nanpercentile(boot_prob_true,  2.5, axis=0)\n","    upper_ci = np.nanpercentile(boot_prob_true, 97.5, axis=0)\n","\n","    return prob_pred_orig, prob_true_orig, lower_ci, upper_ci\n","\n","\n","# ──────────────────────────────────────────────────────────────\n","# STEP 1: Generate calibrated probabilities for each test row in each imputation\n","# ──────────────────────────────────────────────────────────────\n","all_y_probs = []  # will become shape (n_imputations, n_test_rows)\n","\n","for i, cal_model in enumerate(calibrated_models):\n","    X_te = X_test_s_list_xgb[i]\n","    # Predict calibrated probabilities on this imputation’s test set\n","    y_prob_te = cal_model.predict_proba(X_te)[:, 1]\n","    all_y_probs.append(y_prob_te)\n","\n","# Convert to a 2D array: shape = (n_imputations, n_test_rows)\n","all_y_probs = np.vstack(all_y_probs)\n","\n","# STEP 2: Pool probabilities per test row by averaging across imputations\n","# -----------------------------------------------------------------------\n","# Each column corresponds to one test row, so take a mean along axis=0\n","y_prob_pooled = all_y_probs.mean(axis=0)\n","\n","# STEP 3: Obtain a single true‐label array for test rows\n","# -----------------------------------------------------------------------\n","# All imputations share the same true labels in the test set, so we can take any\n","# (e.g., the first one). They should be identical across imputations.\n","y_true = Y_test_list[0]\n","\n","\n","# ──────────────────────────────────────────────────────────────\n","# STEP 4: Compute calibration curve + bootstrap CIs on pooled probabilities\n","# ──────────────────────────────────────────────────────────────\n","prob_pred_orig, prob_true_orig, lower_ci, upper_ci = bootstrap_calibration_curve(\n","    y_true, y_prob_pooled, n_bins=10, n_boot=1000, random_state=42\n",")\n","\n","# STEP 5: Compute Brier score on pooled probabilities\n","# -----------------------------------------------------------------------\n","brier_score = brier_score_loss(y_true, y_prob_pooled)\n","print(f\"Brier Score (on pooled probs): {brier_score:.4f}\")\n","\n","\n","# ──────────────────────────────────────────────────────────────\n","# STEP 6: Plot reliability diagram with 95% CI using pooled probabilities\n","# ──────────────────────────────────────────────────────────────\n","plt.figure(figsize=(8, 6))\n","\n","# Perfect calibration line\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","# Sort bins by mean predicted probability so the line is monotonic\n","sort_idx     = np.argsort(prob_pred_orig)\n","x_sorted     = prob_pred_orig[sort_idx]\n","y_sorted     = prob_true_orig[sort_idx]\n","lower_sorted = lower_ci[sort_idx]\n","upper_sorted = upper_ci[sort_idx]\n","\n","# Plot calibration curve\n","plt.plot(x_sorted, y_sorted, marker='o', color='b', label='Calibration Curve')\n","\n","# Shade 95% CI region\n","plt.fill_between(\n","    x_sorted,\n","    lower_sorted,\n","    upper_sorted,\n","    color='b',\n","    alpha=0.2,\n","    label='95% CI'\n",")\n","\n","##actually display pooled RD\n","plt.xlabel('Mean Predicted Probability (pooled)')\n","plt.ylabel('Fraction of Positives')\n","plt.title('Reliability Diagram with 95% CI (Pooled Across Imputations)')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"NG7g63AGrXh1"},"id":"NG7g63AGrXh1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now we'll generate ROC curve, PR curve, decision curve, and secondary metrics\n","##for models based on each imputation individually.\n","\n","##secondary metrics will be computed at 2 different thresholds: Max F1 and 90% spec\n","\n","# ----------------------------------------------------------------------\n","# 0) Helper: compute confusion‐matrix metrics at one threshold\n","# ----------------------------------------------------------------------\n","def compute_metrics_from_probs(y_true, y_prob, threshold):\n","    y_pred = (y_prob >= threshold).astype(int)\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","\n","    actual_pos = tp + fn\n","    actual_neg = tn + fp\n","    pred_pos   = tp + fp\n","    pred_neg   = tn + fn\n","\n","    accuracy      = (tp + tn) / (actual_pos + actual_neg) if (actual_pos + actual_neg) else 0\n","    sensitivity   = tp / actual_pos if actual_pos else 0           # TPR\n","    specificity   = tn / actual_neg if actual_neg else 0           # TNR\n","    precision     = tp / pred_pos if pred_pos else 0                # PPV\n","    npv           = tn / pred_neg if pred_neg else 0                # NPV\n","    f1            = f1_score(y_true, y_pred) if (tp + fp + fn) else 0\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"Sensitivity (TPR)\": sensitivity,\n","        \"Specificity (TNR)\": specificity,\n","        \"Precision (PPV)\": precision,\n","        \"Negative Predictive Value (NPV)\": npv,\n","        \"F1 Score\": f1\n","    }\n","\n","# ----------------------------------------------------------------------\n","# 1) Gather test labels and calibrated models from the refactored pipeline\n","# ----------------------------------------------------------------------\n","# calibrated_models: list of CalibratedClassifierCV instances, one per imputation\n","# X_test_s_list_xgb : list of “safe”-named test DataFrames (one per imputation)\n","# X_test_s_list     : list of original (un-renamed) test DataFrames\n","# Y_test_list       : list of numpy arrays (or Series) of test labels, one per imputation\n","\n","# Extract calibrated estimators directly\n","calibrators = calibrated_models  # list of CalibratedClassifierCV\n","\n","# Build safe_names_list from the “safe”-named test DataFrames\n","# Each X_test_s_list_xgb[i] has columns already renamed to [\"feat_0\", \"feat_1\", …].\n","safe_names_list = [df.columns.tolist() for df in X_test_s_list_xgb]\n","\n","# ----------------------------------------------------------------------\n","# 2) Loop over each imputation, compute metrics & plot curves\n","# ----------------------------------------------------------------------\n","for i in range(len(X_test_s_list)):\n","    print(f\"\\n\\n===== Imputation {i} Metrics & Curves =====\")\n","\n","    # a) Grab truth and calibrated probabilities for this test fold\n","    y_true      = Y_test_list[i]\n","    calib_model = calibrators[i]\n","    safe_names  = safe_names_list[i]\n","    X_test_df   = X_test_s_list[i]       # original, un-renamed DataFrame\n","\n","    # Rename test DataFrame columns to safe names before predicting\n","    X_te_safe = X_test_df.copy()\n","    X_te_safe.columns = safe_names\n","\n","    # Get calibrated probability of the positive class\n","    y_prob = calib_model.predict_proba(X_te_safe)[:, 1]\n","\n","    # ------------------------------------------------------------------\n","    # 2) ROC Curve + AUROC\n","    # ------------------------------------------------------------------\n","    auroc       = roc_auc_score(y_true, y_prob)\n","    fpr, tpr, _ = roc_curve(y_true, y_prob)\n","    roc_auc_val = sk_auc(fpr, tpr)\n","\n","    plt.figure(figsize=(6, 6))\n","    plt.plot(fpr, tpr, color=\"darkorange\", lw=2,\n","             label=f\"ROC curve (AUC = {roc_auc_val:.3f})\")\n","    plt.plot([0, 1], [0, 1], color=\"black\", lw=2, linestyle=\"--\", label=\"Random\")\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")\n","    plt.title(f\"Imputation {i}: ROC Curve (AUROC={roc_auc_val:.3f})\")\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    # ------------------------------------------------------------------\n","    # 3) Precision‐Recall Curve + AUPRC\n","    # ------------------------------------------------------------------\n","    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n","    pr_auc_val           = sk_auc(recall, precision)\n","\n","    plt.figure(figsize=(6, 5))\n","    plt.plot(recall, precision, color=\"blue\", lw=2,\n","             label=f\"PR curve (AUC = {pr_auc_val:.3f})\")\n","    plt.xlabel(\"Recall\")\n","    plt.ylabel(\"Precision\")\n","    plt.title(f\"Imputation {i}: Precision‐Recall Curve (AUPRC={pr_auc_val:.3f})\")\n","    plt.legend(loc=\"best\")\n","    plt.ylim([0, 1.0])\n","    plt.show()\n","\n","    # ------------------------------------------------------------------\n","    # 4) Confusion Matrix Stats at threshold = 0.50\n","    # ------------------------------------------------------------------\n","    thresh_fixed = 0.50\n","    metrics_050  = compute_metrics_from_probs(y_true, y_prob, thresh_fixed)\n","    brier        = brier_score_loss(y_true, y_prob)\n","\n","    print(f\"\\n– Confusion Matrix Metrics @ threshold = {thresh_fixed:.2f} –\")\n","    cm = confusion_matrix(y_true, (y_prob >= thresh_fixed).astype(int))\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","    print(f\"Accuracy              : {metrics_050['Accuracy']:.3f}\")\n","    print(f\"Sensitivity (TPR)     : {metrics_050['Sensitivity (TPR)']:.3f}\")\n","    print(f\"Specificity (TNR)     : {metrics_050['Specificity (TNR)']:.3f}\")\n","    print(f\"Precision (PPV)       : {metrics_050['Precision (PPV)']:.3f}\")\n","    print(f\"Negative Predictive   : {metrics_050['Negative Predictive Value (NPV)']:.3f}\")\n","    print(f\"F1 Score              : {metrics_050['F1 Score']:.3f}\")\n","    print(f\"Brier Score           : {brier:.4f}\")\n","\n","    # ------------------------------------------------------------------\n","    # 5) Find threshold that maximizes F1 (0.00–1.00 by 0.01)\n","    # ------------------------------------------------------------------\n","    best_f1     = -1.0\n","    best_thresh = None\n","    candidate_ts = np.linspace(0, 1, 101)\n","\n","    for t in candidate_ts:\n","        f1_val = f1_score(y_true, (y_prob >= t).astype(int))\n","        if f1_val > best_f1:\n","            best_f1     = f1_val\n","            best_thresh = t\n","\n","    print(f\"\\nOptimal threshold for max F1: {best_thresh:.2f} (F1 = {best_f1:.3f})\")\n","\n","    # ------------------------------------------------------------------\n","    # 6) Find lowest threshold that yields ≥ 90% specificity (0.00–1.00 by 0.01)\n","    # ------------------------------------------------------------------\n","    thresh_90sp = None\n","    for t in candidate_ts:\n","        tn, fp, fn, tp = confusion_matrix(y_true, (y_prob >= t).astype(int)).ravel()\n","        actual_neg = tn + fp\n","        if actual_neg == 0:\n","            continue\n","        specificity = tn / actual_neg\n","        if specificity >= 0.90:\n","            thresh_90sp = t\n","            break\n","\n","    if thresh_90sp is not None:\n","        tn90 = np.sum((y_true == 0) & (y_prob < thresh_90sp))\n","        fp90 = np.sum((y_true == 0) & (y_prob >= thresh_90sp))\n","        fn90 = np.sum((y_true == 1) & (y_prob < thresh_90sp))\n","        tp90 = np.sum((y_true == 1) & (y_prob >= thresh_90sp))\n","        tnr90 = tn90 / (tn90 + fp90) if (tn90 + fp90) else 0\n","        tpr90 = tp90 / (tp90 + fn90) if (tp90 + fn90) else 0\n","        print(f\"\\nThreshold achieving ≥ 90% specificity: {thresh_90sp:.2f}\")\n","        print(f\"  Specificity (TNR) at {thresh_90sp:.2f}: {tnr90:.3f}\")\n","        print(f\"  Sensitivity (TPR)  at {thresh_90sp:.2f}: {tpr90:.3f}\")\n","    else:\n","        print(\"\\nNo threshold found with ≥ 90% specificity.\")\n","\n","    # ------------------------------------------------------------------\n","    # 7) Decision Curve Analysis (Net Benefit)\n","    # ------------------------------------------------------------------\n","    def net_benefit(y_t, y_p, thresholds):\n","        N  = len(y_t)\n","        NB = []\n","        for t in thresholds:\n","            y_pred_t = (y_p >= t).astype(int)\n","            TP = np.sum((y_t == 1) & (y_pred_t == 1))\n","            FP = np.sum((y_t == 0) & (y_pred_t == 1))\n","            if t == 1.0:\n","                NB.append(0)\n","            else:\n","                NB.append((TP / N) - (FP / N) * (t / (1 - t)))\n","        return NB\n","\n","    decision_thresholds = np.linspace(0.0, 1.0, 101)\n","    NB_vals = net_benefit(y_true, y_prob, decision_thresholds)\n","\n","    prevalence    = np.mean(y_true)\n","    treat_all_nb  = [\n","        (prevalence - (1 - prevalence) * (t / (1 - t))) if t < 1.0 else 0\n","        for t in decision_thresholds\n","    ]\n","    treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","    plt.figure(figsize=(6, 5))\n","    plt.plot(decision_thresholds, NB_vals, label=\"Model\", color=\"darkorange\")\n","    plt.plot(decision_thresholds, treat_all_nb, label=\"Treat All\", color=\"red\", linestyle=\"--\")\n","    plt.plot(decision_thresholds, treat_none_nb, label=\"Treat None\", color=\"blue\", linestyle=\":\")\n","    plt.xlabel(\"Threshold Probability\")\n","    plt.ylabel(\"Net Benefit\")\n","    plt.title(f\"Imputation {i}: Decision Curve Analysis\")\n","    plt.ylim([-0.3, 0.3])\n","    plt.xlim([0, 1.0])\n","    plt.legend(loc=\"best\")\n","    plt.show()\n","\n","    # ------------------------------------------------------------------\n","    # 8) Summary Table for Selected Thresholds\n","    # ------------------------------------------------------------------\n","    performance_metrics   = []\n","    thresholds_to_report  = {\n","        \"Max F1 Threshold\":          best_thresh,\n","        \"90% Specificity Threshold\": thresh_90sp\n","    }\n","\n","    for desc, thr in thresholds_to_report.items():\n","        if thr is not None:\n","            mets = compute_metrics_from_probs(y_true, y_prob, thr)\n","            mets[\"Threshold\"] = f\"{thr:.2f}\"\n","            performance_metrics.append(mets)\n","        else:\n","            print(f\"\\n{desc} not available (no threshold met requirement).\")\n","\n","    df_perf = pd.DataFrame(performance_metrics)\n","    df_perf = df_perf[\n","        [\"Threshold\", \"Accuracy\", \"Sensitivity (TPR)\",\n","         \"Specificity (TNR)\", \"Precision (PPV)\",\n","         \"Negative Predictive Value (NPV)\", \"F1 Score\"]\n","    ]\n","    df_perf.index = thresholds_to_report.keys()\n","\n","    print(\"\\n=== Performance Metrics at Selected Thresholds ===\")\n","    print(df_perf.to_string(float_format=\"%.3f\"))\n","\n","print(\"\\n===== End of All Imputations =====\")\n"],"metadata":{"id":"cXfW6q3ZHNQ-"},"id":"cXfW6q3ZHNQ-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do same thing as above but POOLED results across all imputations\n","##each row is condensed into a single probability (probability averaged across the imputations)\n","\n","# ----------------------------------------------------------------------\n","# 0) Helper: compute confusion‐matrix metrics at one threshold\n","# ----------------------------------------------------------------------\n","def compute_metrics_from_probs(y_true, y_prob, threshold):\n","    y_pred = (y_prob >= threshold).astype(int)\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","\n","    actual_pos = tp + fn\n","    actual_neg = tn + fp\n","    pred_pos   = tp + fp\n","    pred_neg   = tn + fn\n","\n","    accuracy      = (tp + tn) / (actual_pos + actual_neg) if (actual_pos + actual_neg) else 0\n","    sensitivity   = tp / actual_pos if actual_pos else 0           # TPR\n","    specificity   = tn / actual_neg if actual_neg else 0           # TNR\n","    precision     = tp / pred_pos if pred_pos else 0                # PPV\n","    npv           = tn / pred_neg if pred_neg else 0                # NPV\n","    f1            = f1_score(y_true, y_pred) if (tp + fp + fn) else 0\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"Sensitivity (TPR)\": sensitivity,\n","        \"Specificity (TNR)\": specificity,\n","        \"Precision (PPV)\": precision,\n","        \"Negative Predictive Value (NPV)\": npv,\n","        \"F1 Score\": f1\n","    }\n","\n","# ----------------------------------------------------------------------\n","# 1) Gather pooled test‐set probabilities across imputations\n","# ----------------------------------------------------------------------\n","# calibrated_models: list of CalibratedClassifierCV, one per imputation\n","# safe_names_list  : list of lists of safe column names, one per imputation\n","# X_test_s_list    : list of original test DataFrames (one per imputation)\n","# Y_test_list      : list of numpy arrays (or Series) of test labels, one per imputation\n","\n","all_y_probs = []\n","for i, calib_model in enumerate(calibrated_models):\n","    # Rename X_test to safe names\n","    X_te_safe = X_test_s_list[i].copy()\n","    X_te_safe.columns = safe_names_list[i]\n","    # Get calibrated probabilities\n","    y_prob = calib_model.predict_proba(X_te_safe)[:, 1]\n","    all_y_probs.append(y_prob)\n","\n","# Stack (K, N) → average → (N,)\n","y_prob_stack   = np.vstack(all_y_probs)         # shape = (K, N)\n","y_prob_pooled  = y_prob_stack.mean(axis=0)      # shape = (N,)\n","\n","# True labels (assume identical across imputations)\n","y_true = Y_test_list[0]\n","\n","# ----------------------------------------------------------------------\n","# 2) ROC Curve + AUROC on pooled probabilities\n","# ----------------------------------------------------------------------\n","auroc       = roc_auc_score(y_true, y_prob_pooled)\n","fpr, tpr, _ = roc_curve(y_true, y_prob_pooled)\n","roc_auc_val = sk_auc(fpr, tpr)\n","\n","plt.figure(figsize=(6, 6))\n","plt.plot(fpr, tpr, color=\"darkorange\", lw=2,\n","         label=f\"ROC curve (AUC = {roc_auc_val:.3f})\")\n","plt.plot([0, 1], [0, 1], color=\"black\", lw=2, linestyle=\"--\", label=\"Random\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(f\"Pooled ROC Curve (AUROC={roc_auc_val:.3f})\")\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# ----------------------------------------------------------------------\n","# 3) Precision‐Recall Curve + AUPRC on pooled probabilities\n","# ----------------------------------------------------------------------\n","precision, recall, _ = precision_recall_curve(y_true, y_prob_pooled)\n","pr_auc_val           = sk_auc(recall, precision)\n","\n","plt.figure(figsize=(6, 5))\n","plt.plot(recall, precision, color=\"blue\", lw=2,\n","         label=f\"PR curve (AUC = {pr_auc_val:.3f})\")\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(f\"Pooled Precision‐Recall Curve (AUPRC={pr_auc_val:.3f})\")\n","plt.legend(loc=\"best\")\n","plt.ylim([0, 1.0])\n","plt.show()\n","\n","# ----------------------------------------------------------------------\n","# 4) Confusion Matrix Stats at threshold = 0.50 on pooled probabilities\n","# ----------------------------------------------------------------------\n","thresh_fixed = 0.50\n","metrics_050  = compute_metrics_from_probs(y_true, y_prob_pooled, thresh_fixed)\n","brier        = brier_score_loss(y_true, y_prob_pooled)\n","\n","print(f\"\\n– Pooled Confusion Matrix Metrics @ threshold = {thresh_fixed:.2f} –\")\n","cm = confusion_matrix(y_true, (y_prob_pooled >= thresh_fixed).astype(int))\n","print(\"Confusion Matrix:\")\n","print(cm)\n","print(f\"Accuracy              : {metrics_050['Accuracy']:.3f}\")\n","print(f\"Sensitivity (TPR)     : {metrics_050['Sensitivity (TPR)']:.3f}\")\n","print(f\"Specificity (TNR)     : {metrics_050['Specificity (TNR)']:.3f}\")\n","print(f\"Precision (PPV)       : {metrics_050['Precision (PPV)']:.3f}\")\n","print(f\"Negative Predictive   : {metrics_050['Negative Predictive Value (NPV)']:.3f}\")\n","print(f\"F1 Score              : {metrics_050['F1 Score']:.3f}\")\n","print(f\"Brier Score           : {brier:.4f}\")\n","\n","# ----------------------------------------------------------------------\n","# 5) Find threshold that maximizes F1 on pooled predictions\n","# ----------------------------------------------------------------------\n","best_f1     = -1.0\n","best_thresh = None\n","candidate_ts = np.linspace(0, 1, 101)\n","\n","for t in candidate_ts:\n","    f1_val = f1_score(y_true, (y_prob_pooled >= t).astype(int))\n","    if f1_val > best_f1:\n","        best_f1     = f1_val\n","        best_thresh = t\n","\n","print(f\"\\nOptimal threshold for max F1 (pooled): {best_thresh:.2f} (F1 = {best_f1:.3f})\")\n","\n","# ----------------------------------------------------------------------\n","# 6) Find threshold that yields ≥ 90% specificity on pooled predictions\n","# ----------------------------------------------------------------------\n","thresh_90sp = None\n","for t in candidate_ts:\n","    tn, fp, fn, tp = confusion_matrix(y_true, (y_prob_pooled >= t).astype(int)).ravel()\n","    actual_neg = tn + fp\n","    if actual_neg == 0:\n","        continue\n","    specificity = tn / actual_neg\n","    if specificity >= 0.90:\n","        thresh_90sp = t\n","        break\n","\n","if thresh_90sp is not None:\n","    tn90 = np.sum((y_true == 0) & (y_prob_pooled <  thresh_90sp))\n","    fp90 = np.sum((y_true == 0) & (y_prob_pooled >= thresh_90sp))\n","    fn90 = np.sum((y_true == 1) & (y_prob_pooled <  thresh_90sp))\n","    tp90 = np.sum((y_true == 1) & (y_prob_pooled >= thresh_90sp))\n","    tnr90 = tn90 / (tn90 + fp90) if (tn90 + fp90) else 0\n","    tpr90 = tp90 / (tp90 + fn90) if (tp90 + fn90) else 0\n","    print(f\"\\nThreshold achieving ≥ 90% specificity (pooled): {thresh_90sp:.2f}\")\n","    print(f\"  Specificity (TNR) at {thresh_90sp:.2f}: {tnr90:.3f}\")\n","    print(f\"  Sensitivity (TPR)  at {thresh_90sp:.2f}: {tpr90:.3f}\")\n","else:\n","    print(\"\\nNo threshold found with ≥ 90% specificity (pooled).\")\n","\n","# ----------------------------------------------------------------------\n","# 7) Decision Curve Analysis (Net Benefit) on pooled predictions\n","# ----------------------------------------------------------------------\n","def net_benefit(y_t, y_p, thresholds):\n","    N  = len(y_t)\n","    NB = []\n","    for t in thresholds:\n","        y_pred_t = (y_p >= t).astype(int)\n","        TP = np.sum((y_t == 1) & (y_pred_t == 1))\n","        FP = np.sum((y_t == 0) & (y_pred_t == 1))\n","        if t == 1.0:\n","            NB.append(0)\n","        else:\n","            NB.append((TP / N) - (FP / N) * (t / (1 - t)))\n","    return NB\n","\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","NB_vals = net_benefit(y_true, y_prob_pooled, decision_thresholds)\n","\n","prevalence    = np.mean(y_true)\n","treat_all_nb  = [\n","    (prevalence - (1 - prevalence) * (t / (1 - t))) if t < 1.0 else 0\n","    for t in decision_thresholds\n","]\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","plt.figure(figsize=(6, 5))\n","plt.plot(decision_thresholds, NB_vals, label=\"Model\", color=\"darkorange\")\n","plt.plot(decision_thresholds, treat_all_nb, label=\"Treat All\", color=\"red\", linestyle=\"--\")\n","plt.plot(decision_thresholds, treat_none_nb, label=\"Treat None\", color=\"blue\", linestyle=\":\")\n","plt.xlabel(\"Threshold Probability\")\n","plt.ylabel(\"Net Benefit\")\n","plt.title(\"Pooled Decision Curve Analysis\")\n","plt.ylim([-0.3, 0.3])\n","plt.xlim([0, 1.0])\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","# ----------------------------------------------------------------------\n","# 8) Summary Table for Selected Thresholds (Pooled)\n","# ----------------------------------------------------------------------\n","performance_metrics   = []\n","thresholds_to_report  = {\n","    \"Max F1 Threshold\":          best_thresh,\n","    \"90% Specificity Threshold\": thresh_90sp\n","}\n","\n","for desc, thr in thresholds_to_report.items():\n","    if thr is not None:\n","        mets = compute_metrics_from_probs(y_true, y_prob_pooled, thr)\n","        mets[\"Threshold\"] = f\"{thr:.2f}\"\n","        performance_metrics.append(mets)\n","    else:\n","        print(f\"\\n{desc} not available (no threshold met requirement).\")\n","\n","df_perf = pd.DataFrame(performance_metrics)\n","df_perf = df_perf[\n","    [\"Threshold\", \"Accuracy\", \"Sensitivity (TPR)\",\n","     \"Specificity (TNR)\", \"Precision (PPV)\",\n","     \"Negative Predictive Value (NPV)\", \"F1 Score\"]\n","]\n","df_perf.index = thresholds_to_report.keys()\n","\n","print(\"\\n=== Pooled Performance Metrics at Selected Thresholds ===\")\n","print(df_perf.to_string(float_format=\"%.3f\"))\n"],"metadata":{"id":"-YanQlePHiXk"},"id":"-YanQlePHiXk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##compute 95% CI for AUROC and AUPRC based on 1000-sample bootstrapping\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 0) Gather inputs from your pipeline:\n","#    • X_test_s_list     : list of DataFrames (one per imputation) of test features (un‐renamed)\n","#    • Y_test_list       : list of numpy arrays (one per imputation) of test labels\n","#    • calibrated_models : list of CalibratedClassifierCV models (one per imputation)\n","#    • safe_names_list   : list of lists of “safe” feature names (one per imputation)\n","# ───────────────────────────────────────────────────────────────────────────────\n","\n","K = len(X_test_s_list)\n","N = len(Y_test_list[0])  # number of patients in each imputed test set\n","\n","# 1) For each imputation, compute y_prob_i (length N)\n","all_probs = np.zeros((K, N))\n","for i in range(K):\n","    X_te_safe = X_test_s_list[i].copy()\n","    X_te_safe.columns = safe_names_list[i]\n","    all_probs[i, :] = calibrated_models[i].predict_proba(X_te_safe)[:, 1]\n","\n","# 2) Average across imputations → one probability per patient:\n","y_prob_pooled = all_probs.mean(axis=0)   # shape = (N,)\n","\n","# 3) True labels (same for every imputation)\n","y_true = Y_test_list[0]  # assume identical for all i\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 4) Compute “pooled” AUROC & AUPRC (no bootstrap yet)\n","# ───────────────────────────────────────────────────────────────────────────────\n","pooled_auroc = roc_auc_score(y_true, y_prob_pooled)\n","\n","precision_all, recall_all, _ = precision_recall_curve(y_true, y_prob_pooled)\n","pooled_auprc = sk_auc(recall_all, precision_all)\n","\n","print(f\"Pooled AUROC (no CI) = {pooled_auroc:.3f}\")\n","print(f\"Pooled AUPRC (no CI) = {pooled_auprc:.3f}\")\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 5) Bootstrap to get 95% CI (resample the N patients, NOT K·N)\n","# ───────────────────────────────────────────────────────────────────────────────\n","n_boot   = 1000\n","rng      = np.random.RandomState(0)\n","\n","boot_aurocs = np.zeros(n_boot)\n","boot_auprcs = np.zeros(n_boot)\n","\n","for b in range(n_boot):\n","    idx = rng.randint(0, N, size=N)\n","    y_b  = y_true[idx]\n","    p_b  = y_prob_pooled[idx]\n","\n","    try:\n","        boot_aurocs[b] = roc_auc_score(y_b, p_b)\n","    except ValueError:\n","        boot_aurocs[b] = np.nan\n","\n","    try:\n","        prec_b, rec_b, _ = precision_recall_curve(y_b, p_b)\n","        boot_auprcs[b]     = sk_auc(rec_b, prec_b)\n","    except ValueError:\n","        boot_auprcs[b] = np.nan\n","\n","boot_aurocs = boot_aurocs[~np.isnan(boot_aurocs)]\n","boot_auprcs = boot_auprcs[~np.isnan(boot_auprcs)]\n","\n","lower_auroc = np.percentile(boot_aurocs, 2.5)\n","upper_auroc = np.percentile(boot_aurocs, 97.5)\n","\n","lower_auprc = np.percentile(boot_auprcs, 2.5)\n","upper_auprc = np.percentile(boot_auprcs, 97.5)\n","\n","print(f\"Pooled AUROC = {pooled_auroc:.3f}   95% CI = [{lower_auroc:.3f}, {upper_auroc:.3f}]\")\n","print(f\"Pooled AUPRC = {pooled_auprc:.3f}   95% CI = [{lower_auprc:.3f}, {upper_auprc:.3f}]\")"],"metadata":{"id":"ibxQxU9pJeBk"},"id":"ibxQxU9pJeBk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##generate SHAP importance value visualization for top 20 vars\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 1: Compute SHAP values for each imputation’s training set\n","# ───────────────────────────────────────────────────────────────\n","all_shap_full = []     # will hold arrays of shape (N, F) for each imputation\n","orig_feature_names = X_train_s_list[0].columns.tolist()  # assume same columns every imputation\n","\n","for i, model in enumerate(final_models):\n","    # A) Safe‐named training DataFrame\n","    X_tr_safe = X_train_s_list_xgb[i]  # shape = (N, F)\n","\n","    # B) Compute SHAP values on the safe‐named DataFrame\n","    explainer = shap.TreeExplainer(model)\n","    shap_vals = explainer.shap_values(X_tr_safe)  # shape = (N, F)\n","\n","    all_shap_full.append(shap_vals)\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 2: Pool SHAP by averaging across imputations per row\n","# ───────────────────────────────────────────────────────────────\n","# A) Stack into (K, N, F)\n","shap_stack    = np.stack(all_shap_full, axis=0)    # shape = (K, N, F)\n","# B) Average along axis=0 → (N, F)\n","shap_pooled   = shap_stack.mean(axis=0)            # shape = (N, F)\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 3: Compute mean(|SHAP|) from pooled SHAP and rank features\n","# ───────────────────────────────────────────────────────────────\n","mean_abs_pooled = np.abs(shap_pooled).mean(axis=0)     # shape = (F,)\n","shap_mean_series = pd.Series(mean_abs_pooled, index=orig_feature_names)\n","overall_ranking = shap_mean_series.sort_values(ascending=False)\n","\n","# Display the top 20 overall\n","top20_overall = overall_ranking.head(20)\n","print(\"🔥 Top 20 features overall (pooled across imputations):\")\n","display(top20_overall)\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 4: Plot the overall top 20\n","# ───────────────────────────────────────────────────────────────\n","fig, ax = plt.subplots(figsize=(10, 6))\n","ax.barh(top20_overall.index[::-1], top20_overall.values[::-1], color=\"dodgerblue\")\n","ax.set_xlabel(\"Average |SHAP| (pooled across imputations)\")\n","ax.set_title(\"Overall Top 20 Features by Mean |SHAP| (Pooled Across Imputations)\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"Ul7oDthN39t3"},"id":"Ul7oDthN39t3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##generate SHAP beeswarm plot for top 20 vars\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 0: Ensure `top20_overall` is already defined:\n","#   A pandas Series where index = feature_name, value = avg mean(|SHAP|).\n","# ───────────────────────────────────────────────────────────────\n","top20_features = list(top20_overall.index)  # e.g. [\"AGEYEARS\", \"TBIGCSMOTOR\", …]\n","\n","# Prepare lists to collect SHAP arrays and (optional) raw feature values\n","all_shap_top20_list   = []\n","all_featvals_top20_df = None  # we'll take raw feature values from imputation 0\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 1: For each imputation, extract the SHAP values of the top 20\n","# ───────────────────────────────────────────────────────────────\n","for i, model in enumerate(final_models):\n","    # A) Original training DataFrame (with original column names)\n","    X_tr_full = X_train_s_list[i]\n","    orig_names = X_tr_full.columns.tolist()\n","\n","    # B) Safe‐named version used to train XGBoost\n","    X_tr_safe = X_train_s_list_xgb[i]\n","    safe_names = X_tr_safe.columns.tolist()\n","\n","    # C) Compute SHAP values on the safe‐named training DataFrame\n","    explainer = shap.TreeExplainer(model)\n","    shap_vals_full = explainer.shap_values(X_tr_safe)  # shape = (N, F)\n","\n","    # D) Identify indices of top‐20 features within the full feature list\n","    full_cols  = orig_names  # ordering corresponds to safe_names\n","    top20_idxs = [full_cols.index(feat) for feat in top20_features]\n","\n","    # E) Extract only those SHAP columns (shape → [N, 20])\n","    shap_top20 = shap_vals_full[:, top20_idxs]\n","    all_shap_top20_list.append(shap_top20)\n","\n","    # F) For coloring, capture raw feature values of top20 from imputation 0\n","    if i == 0:\n","        all_featvals_top20_df = X_tr_full[top20_features].copy()\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 2: Pool SHAP values by averaging across imputations per row\n","# ───────────────────────────────────────────────────────────────\n","# A) Stack into (K, N, 20)\n","shap_top20_stack   = np.stack(all_shap_top20_list, axis=0)   # shape = (K, N, 20)\n","# B) Average along axis=0 → (N, 20)\n","shap_top20_pooled  = shap_top20_stack.mean(axis=0)           # shape = (N, 20)\n","\n","# ───────────────────────────────────────────────────────────────\n","# STEP 3: Build a beeswarm (dot) plot for these 20 features (pooled)\n","# ───────────────────────────────────────────────────────────────\n","plt.figure(figsize=(10, 6))\n","shap.summary_plot(\n","    shap_top20_pooled,\n","    all_featvals_top20_df,\n","    feature_names=top20_features,\n","    plot_type=\"dot\",\n","    show=False\n",")\n","plt.title(\"Beeswarm of Top-20 Features (Pooled SHAP Across Imputations)\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"D8EdkNptzhRe"},"id":"D8EdkNptzhRe","execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1DFrM2kQIaxxoreKKfMJY8bZ75pnIBOBL","timestamp":1734555115141},{"file_id":"1XL3SGHIBPO06uNNL8pc4jbgyODiCHYmT","timestamp":1734454404403},{"file_id":"1DYwnmjwYAdIuKZSkwpMlcAF8yUXEA0x7","timestamp":1728001604398}],"gpuType":"V28"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}